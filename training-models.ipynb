{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-23T02:01:42.269724Z",
     "start_time": "2026-01-23T02:01:41.703734Z"
    }
   },
   "source": [
    "#criei o repositório para guardar as anotações do estudos de modelos (principalmente de regressão\n",
    "\n",
    "#Regressão Polinomial\n",
    "#criação de dados quadráticos não lineares com ruído\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "m = 100 # instâncias de treinamento\n",
    "X = 6 * np.random.rand(m,1) - 3\n",
    "y = 0.5 * X**2 + X + 2 + np.random.randn(m,1)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-23T02:07:52.174959Z",
     "start_time": "2026-01-23T02:07:50.882423Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#para ajustar aos dados, usamos a classe PolynomialFeatures do SKLearn para transformar dados de treino, adicionando o quadrado de cada característica no conjunto de treinamento como uma nova característica\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "# include_bias=False: Evita adicionar uma coluna extra de 1s (que representa o viés/x^0).\n",
    "# isso é feito porque a maioria dos modelos do SKLearn (como LinearRegression) já\n",
    "# calcula o intercepto automaticamente, evitando assim duplicidade no termo de viés.\n",
    "poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = poly_features.fit_transform(X)\n",
    "X[0]"
   ],
   "id": "23c984bc3ddc8932",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.54051377])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-23T02:08:00.420172Z",
     "start_time": "2026-01-23T02:08:00.408171Z"
    }
   },
   "cell_type": "code",
   "source": "X_poly[0]",
   "id": "e9a903e9a49a90e2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.54051377,  2.37318268])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2026-01-23T02:09:58.899214Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# X_poly tem a caracterísitica original de X mais o quadrado dessa característica, dando para ajustar os dados no LinearRegression\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_poly, y)\n",
    "\n",
    "lin_reg.intercept_, lin_reg.coef_"
   ],
   "id": "e3080669ab0be4ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# em uma regressão polinomial, o modelo consegue encontrar relações entre várias caracterísiticas, coisa que a regressão linear não consegue. Isso por conta do PolynomialFeatures(degree=d)\n",
    "\n",
    "#PolynomialFeatures(degree=3) não adiciona somente as caracteristicas a^2, a^3, b^2, b^3, mas também as combinações de ab, a^2b, ab^2\n",
    "\n",
    "plt.scatter(X , y)\n",
    "plt.plot(X , lin_reg.predict(X), color='red')"
   ],
   "id": "c18d6928965c7193"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#antes de plotar as curvas de aprendizado, o livro fala sobre utilizar a validação cruzada para verificar se o modelo está se sobre ou subajustando\n",
    "#primeiro preciso dividir os dados em treino e teste\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores_test = cross_val_score(lin_reg, X_train, y_train, cv=10, scoring='neg_mean_squared_error')"
   ],
   "id": "c585935eca7a9e30"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
